# Identifying the issue

In this section we investigate the underlying issue that causes there to be an problem when we try to calibrate a model with a data set that has very unbalanced numbers of observations from different parts of the system. We do this by breaking the problem into parts to investigate the individual influence of model structural error and data bias when calibrating with balanced and unbalanced datasets. We start with the idealised situation of a perfect and a perfect calibration dataset with a balanced number of observations for each part of the system. 

## Perfect model and balanced data Pb

Looking first at the parameters (Fig. (\ref{fig:perModbalDataPar}) we find that the 'true' parameters are largely recaptured by the calibration. The marginal posterior distributions are centred around the 'truth' line and the uncertainty versus the prior has reduced significantly. The model outputs for NEE, Cv and Cs are also centred around the truth line with the 50% quantile line matching the truth line closely. The posterior uncertainty is small and the predictive interval matches the uncertainty in the data as would be expected. This first calibration can be considered as a control against which all subsequent runs can be compared.

```{r include=FALSE}
newPars <- refPars$best
names(newPars) = row.names(refPars)
parSel = c(defParms, nvar)
rm(obsSel)
isLow = NULL
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaultsOld(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)
  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[,2] - obs[,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))

}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])
out1 <- fitVSEM("run1.RData")

MAP  <- calcMAP("MAP.Rdata")
```


```{r echo=FALSE, out.width="45%", out.height="45%",fig.show='hold',fig.align='center', fig.cap="\\label{fig:Par}blank for now"}
knitr::include_graphics(c("/home/david/TG15FM/pDistr/KEXT.png","/home/david/TG15FM/pDistr/LUE.png","/home/david/TG15FM/pDistr/tauV.png","/home/david/TG15FM/pDistr/tauS.png","/home/david/TG15FM/pDistr/Cs.png","/home/david/TG15FM/pDistr/Cv.png"))
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:perModbalDataOut}Perfect model, balanced data (NEE, Cv, Cs: 2048 obs). Observations included in the calibration marked with a '+'. Red line 50% quantile posterior distribution. Green line is the 'true' model output. Dark brown shading 2.5% 97.5% quantile posterior distribution. Light brown shading 2.5% 97.5% predictive interval."}
plotOutputs(out1,refPars)
```

## Perfect model and unbalanced data Pu

We now consider what happens when we have a large imbalance in the calibration data. We do this by thinning out the number of observations for Cv from 2048 to just six observations whilst retaining the original 2048 observations for NEE and Cs; thus creating an O(3) imbalance. After calibration the parameters are still largely centred on the 'truth' line. For KEXT and especially tauV and Cv there has been an increase in marginal uncertainty but this would be expected since we have included less information in the calibration. In figure ... we see the outputs for Cv and Cs for Pu. For the remaining calibrations we do not include plots of NEE as the plot does not change from that shown previously for Pb. For Cs also, there is little change from before (Pb) when the data was balanced. The Cv plot shows the six observations that were retained in the calibration. The posterior is still centred on the truth line with a larger posterior uncertainty as might be expected since far fewer data have been included. These results show that creating an imbalanced does not cause an issue in the calibration other than increasing the uncertainty. 

```{r include=FALSE}
newPars <- refPars$best
parSel = c(defParms, nvar)
obsSel <- c(1,202,390,550,750,920)*2.0
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)

  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

## Prior
prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out2 <- fitVSEM("run2.RData")

MAPunbal <- calcMAP("MAPunbal.Rdata")
```

## Model with error and balanced data Eb

Here we create a known significant structural error in the model by effectively removing the root pool from the model see section... After calibration a number of parameters are now quite far away from their 'true' values. This is especially dramatic for tauV, which controls the turnover of vegetation, and is now lower, so that the rate of turnover of the vegetation pool has now more than doubled. All the allocated carbon is now to the vegetation pool so the increased turnover rate tries to compensate for this error in the model. Hence, we can see that the departure of the parameters from their 'true' value has the effect of 'absorbing' some of the influence of model structural error. The result is that the model outputs have not changed significantly (see supplementary material) from the perfect model run. These results show that model performance against available data can still be acceptable even when very signifcant model errors are present so long as changed parameters settings somewhat 'mask out' the influence of the error. 

```{r include=FALSE}

## Likelihood: Gaussian 2048 obs for each of NEE, Cv and Cs
newPars <- refPars$best
names(newPars) = row.names(refPars)
newPars["Av"]  <- 1.0
newPars["Cr"] <- 0.0
parSel = c(defParms, nvar)
rm(obsSel)
isLow = NULL
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)
  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[,2] - obs[,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))

}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out3 <- fitVSEM("run3.RData")

MAPErr <- calcMAP("MAPErr.Rdata")
```

## Model with error and unbalanced data Eu

We now test what happens when we combine the influences investigated in the previous two sections. This calibration includes both the model structural error and the large data imbalance. Looking first at the marginal parameter distributions after calibration there are changes versus the Eb calibration which are significant but not huge. In production, KEXT has increased and LUE has decreased slightly compensating for each other. Belowground, parameters Cs and tauS are now closer to their 'true' value than in Eb. Similarly aboveground, tauV is now closer to its 'true' value then in the Eb calibration. In general, the change in parameters to compensate for the model structural error is less than for Eb. Looking at outputs for Cv and Cs, the calibration is fine for Cs but drifts away significantly from the six vegetation measurements. This is the typical 'picture' for calibrations with a large data imbalance, the sparsely measured parts of the system are ignored at the expense of the parts of the system with many observations. This calibration, along with the previous two (Pu and Eb), make it clear that the model structural error is key in creating an issue when calibrating a model with a large imbalance in data. 

```{r include=FALSE}
newPars <- refPars$best
names(newPars) = row.names(refPars)
newPars["Av"]  <- 1.0
newPars["Cr"] <- 0.0
parSel = c(defParms, nvar)
obsSel <- c(1,202,390,550,750,920)*2.0
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)

  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out5 <- fitVSEM("run5.RData")

MAPErrunbal <- calcMAP("MAPErrunbal.Rdata")
```

## Perfect model and balanced data with a multiplicative bias PbB

We now investigate the influence of data bias on the calibration. As presented in section..., we create a multiplicative data bias by multiplying the soil carbon pool by two. Similarly to Eb, parameters in the calibration do not all recover their 'true' values and hence 'absorb' the influence of data error. As might be expected this is most dramatic for the belowground parameters. The Cs parameter increases significantly and the tauS also increases, slowing the turnover. This has the effect of increasing the soil carbon pool to match the erroneous data. As before, these departures of the parameters from their 'true' value allows there to be a reasonably close match between the model outputs after calibration and the data (supplementary material). 

```{r include=FALSE}
obs.orig     <- obs
obs[,3] <- obs[,3] * 2.0

newPars <- refPars$best
names(newPars) = row.names(refPars)
parSel = c(defParms, nvar)
rm(obsSel)
isLow = NULL
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaultsOld(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)
  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[,2] - obs[,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out12 <- fitVSEM("run12.RData")
obs <- obs.orig
```

## Perfect model and unbalanced data with a multiplicative bias PuB

We now add the effect of unbalanced data to the calibration with the large data bias. We look first at the parameter marginal distributions after calibration. In carbon production, KEXT has increased markedly increasing the carbon inputted to the system. This is counteracted slightly by LUE. Aboveground Cv is much larger tauV is smaller increasing the turnover to the soil. This has the combined effect of passing on more carbon to the soil. Belowground, tauS was already large, Cs has decreased versus the PbB calibration. As the output plots, show the calibration is now effectively completely ignoring the six vegetation observations with all the 'effort' going into matching the many erroneous soil carbon observations. This is in effect just a more dramatic example of what we observed in Eu. These results show there can be issues calibrating with unbalanced datasets where there is a model structural error or a significant data bias.


```{r include=FALSE}
obs[,3] <- obs[,3] * 2.0

newPars <- refPars$best
parSel = c(defParms, nvar)
obsSel <- c(1,202,390,550,750,920)*2.0
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaultsOld(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)

  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out13 <- fitVSEM("run13.RData")
obs <- obs.orig
```

## Model with error and unbalanced data with a multiplicative bias EuB

Now we combine the model structural error with the data bias and run the calibration with the unbalanced dataset. The two errors slightly counteract each other since the erroneous increase in the vegetation pool due to the missing root pool model error is beneficial in feeding more carbon to the soil pool through increased vegetative turnover to match the errorneous data. Therefore Cv can be closer to its true value versus PuB whereas tauV is further away from its 'true' value facilitating greater turnover. The model outputs are very similar to PuB with the data error dominating. 

```{r include=FALSE}
obs[,3] <- obs[,3] * 2.0

newPars <- refPars$best
names(newPars) = row.names(refPars)
newPars["Av"]  <- 1.0
newPars["Cr"] <- 0.0
parSel = c(defParms, nvar)
obsSel <- c(1,202,390,550,750,920)*2.0
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaultsOld(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR)

  diff       <- c(predicted[,1] - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(predicted[,3] - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out17 <- fitVSEM("run17.RData")
obs <- obs.orig
```


# Diagnosing the issue

## Comparing model output with virtual data as truth.

Moving on from identifying the issue in the previous section, here we develop a tool for
helping to diagnose at what point and to what extent having unbalanced data in Bayesian
calibration (BC) becomes an issue when models and data are imperfect. 

This is done by running a number of calibrations with perfect and imperfect models where
the quantity and imbalance of data used increases with each calibration. Here we chose an
increasing power series of two (2^3^,2^4^ ... 2^11^) for the increase in the quantity of
calibration data; eight calibrations in all. In the balanced data BC case, quantities of
NEE, vegetative carbon and soil carbon data included in the BC all increased in tandem in
each subsequent calibration. For the unbalanced BC case, NEE and soil carbon data
increased as before but the quantity of vegetative carbon data included in the BC was held
fixed at six data points for each of the eight calibrations. After running the
calibrations the VSEM was rerun with the maximum a posteriori (MAP) vector and the RMS
difference with the 'true' data was calculated and plotted (Fig. \ref{fig:rmsMAPTruth}).

The figure shows broad similarity in results except for vegetative carbon case when the
model has an error and where there is an imbalanced in calibration data. In general, the
RMS difference has a tendency to go down as the quantity of data included in calibration
increases. There is also a marked grouping of results with the perfect model getting
closer to the data than the model with the error, as might be expected. For NEE and soil
carbon with an imperfect model, the unbalanced calibration gets closer to the data than
the balanced calibration especially as the quantity of calibration data increases. This is
in marked contrast to vegetative carbon where RMS differences increase significantly as
quantity of calibration data increases when the model has an error and when there is an
imbalanced in calibration data. This increase in RMS difference for vegetative carbon
occurs in tandem with the decreases noted already from NEE and soil carbon. This signature
of increasing RMS difference for the low quantity data output versus the decreasing RMS
difference for the high quantity can be used to diagnose when large imbalances in
calibrations data with imperfect models and data start to become an issue. In this case,
it appears after the quantity of data included in the calibration exceeds 32 but this will
be different for each model, likelihood function and for each dataset used in
calibrations.


```{r include=FALSE}
source("gridArrangeSharedLegend.R")

## csel <- map(2^{0:8},function(i) seq(1,2048,i))

## loadMAP <- function(fname){
##   load(paste(exptPath,fname,sep=""))
##   invisible(MAP)
## }

## MAP         <- loadMAP("MAP.Rdata")
## MAPunbal    <- loadMAP("MAPunbal.Rdata")
## MAPErr      <- loadMAP("MAPErr.Rdata")
## MAPErrunbal <- loadMAP("MAPErrunbal.Rdata")

calcRMS <- function(istep,fldno,tselect,fld,MAPfld){
    x          <- createMixWithDefaults(MAPfld[istep,], newPars, parSel)
    predicted  <- VSEM(x[-nvar], PAR)
    ofld       <- fld
    return(sqrt(mean((predicted[tselect,fldno] - ofld[tselect,fldno])**2)))
}

tt <- tibble::tibble ( istep=1:9)

newPars <- refPars$best
names(newPars) = row.names(refPars)
parSel = c(defParms, nvar)
newPars["Av"]  <- 1.0
newPars["Cr"]  <- 0.0
BCMAPRMSObs <- tt %>% mutate(NEERMSErrunbal=map_dbl(istep,function(i) calcRMS(i,fldno=1,tselect=1:ndays,fld=referenceData,MAPfld=MAPErrunbal))) %>%
                      mutate(CvRMSErrunbal =map_dbl(istep,function(i) calcRMS(i,fldno=2,tselect=1:ndays,fld=referenceData,MAPfld=MAPErrunbal))) %>%
                      mutate(CsRMSErrunbal =map_dbl(istep,function(i) calcRMS(i,fldno=3,tselect=1:ndays,fld=referenceData,MAPfld=MAPErrunbal))) %>%
                      mutate(NEERMSErr     =map_dbl(istep,function(i) calcRMS(i,fldno=1,tselect=1:ndays,fld=referenceData,MAPfld=MAPErr     ))) %>%
                      mutate(CvRMSErr      =map_dbl(istep,function(i) calcRMS(i,fldno=2,tselect=1:ndays,fld=referenceData,MAPfld=MAPErr     ))) %>%
                      mutate(CsRMSErr      =map_dbl(istep,function(i) calcRMS(i,fldno=3,tselect=1:ndays,fld=referenceData,MAPfld=MAPErr     ))) %>%
                      mutate(noObs=map_int(istep,function(i) length(csel[[i]])))

newPars["Av"]  <- 0.5
newPars["Cr"]  <- 3.0
BCMAPRMSObs <- BCMAPRMSObs %>%
                      mutate(NEERMSunbal   =map_dbl(istep,function(i) calcRMS(i,fldno=1,tselect=1:ndays,fld=referenceData,MAPfld=MAPunbal   ))) %>%
                      mutate(CvRMSunbal    =map_dbl(istep,function(i) calcRMS(i,fldno=2,tselect=1:ndays,fld=referenceData,MAPfld=MAPunbal   ))) %>%
                      mutate(CsRMSunbal    =map_dbl(istep,function(i) calcRMS(i,fldno=3,tselect=1:ndays,fld=referenceData,MAPfld=MAPunbal   ))) %>%
                      mutate(NEERMS        =map_dbl(istep,function(i) calcRMS(i,fldno=1,tselect=1:ndays,fld=referenceData,MAPfld=MAP        ))) %>%
                      mutate(CvRMS         =map_dbl(istep,function(i) calcRMS(i,fldno=2,tselect=1:ndays,fld=referenceData,MAPfld=MAP        ))) %>%
                      mutate(CsRMS         =map_dbl(istep,function(i) calcRMS(i,fldno=3,tselect=1:ndays,fld=referenceData,MAPfld=MAP        )))

p1 <- ggplot(data = BCMAPRMSObs, aes(x=noObs)) +
    geom_point(aes(y = NEERMS,colour="Perfect Model")) +
    geom_line (aes(y = NEERMS,colour="Perfect Model")) +
    geom_point(aes(y = NEERMSunbal,colour="Perfect Model UnBal Data")) +
    geom_line (aes(y = NEERMSunbal,colour="Perfect Model UnBal Data")) +
    geom_point(aes(y = NEERMSErr,colour="Model with Error")) +
    geom_line (aes(y = NEERMSErr,colour="Model with Error")) +
    geom_point(aes(y = NEERMSErrunbal,colour="Model with Error UnBal Data")) +
    geom_line (aes(y = NEERMSErrunbal,colour="Model with Error UnBal Data"))+
    labs(x = " ", y="RMS NEE")

p2 <- ggplot(data = BCMAPRMSObs, aes(x=noObs)) +
    geom_point(aes(y = CvRMS,colour="Perfect Model")) +
    geom_line (aes(y = CvRMS,colour="Perfect Model")) +
    geom_point(aes(y = CvRMSunbal,colour="Perfect Model UnBal Data")) +
    geom_line (aes(y = CvRMSunbal,colour="Perfect Model UnBal Data")) +
    geom_point(aes(y = CvRMSErr,colour="Model with Error")) +
    geom_line (aes(y = CvRMSErr,colour="Model with Error")) +
    geom_point(aes(y = CvRMSErrunbal,colour="Model with Error UnBal Data"))+
    geom_line (aes(y = CvRMSErrunbal,colour="Model with Error UnBal Data"))+
    labs(x = " ", y="RMS vegetative carbon")

p3 <- ggplot(data = BCMAPRMSObs, aes(x=noObs)) +
    geom_point(aes(y = CsRMS,colour="Perfect Model")) +
    geom_line (aes(y = CsRMS,colour="Perfect Model")) +
    geom_point(aes(y = CsRMSunbal,colour="Perfect Model UnBal Data")) +
    geom_line (aes(y = CsRMSunbal,colour="Perfect Model UnBal Data")) +
    geom_point(aes(y = CsRMSErr,colour="Model with Error")) +
    geom_line (aes(y = CsRMSErr,colour="Model with Error")) +
    geom_point(aes(y = CsRMSErrunbal,colour="Model with Error UnBal Data")) +
    geom_line (aes(y = CsRMSErrunbal,colour="Model with Error UnBal Data"))+
    labs(x = "Number of observations included in the calibration", y="RMS soil carbon")
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:rmsMAPTruth}Each point in the three graphs (NEE, vegetative carbon, and soil carbon) represents the RMS difference between the VSEM model and the 'truth' run with different maximum a posteriori (MAP) vectors. The MAP vector at each point is obtained from a Bayesian calibration (BC) where the quantity of data included in the BC increases in a sequence along the x-axis following the exponentiation of base two. For the balanced calibration case (red and cyan) vegetative carbon data increases in tandem with NEE and soil carbon. For the unbalanced calibration case (green and purple) the quantity of vegetative carbon data is held fixed at six data values for each point along the x-axis. The VSEM model is either 'perfect' (cyan and purple) or has a known error (red and green) relative to the 'true' data that was derived from it."}
grid_arrange_shared_legend(p1, p2, p3, ncol = 1, nrow = 3)

```

## Comparing model output against "obervations"

The diagnosis made in the previous section had the benefit of access to the 'true' data
and a perfect model. Unfortunately this is never the case for real world ecological model
calibrations. Therefore, here we have repeated the previous graph
Fig.(\ref{fig:rmsMAPTruth}) with just the imperfect model and the imbalanced calibration,
but with RMS differences now calculated against observations (NEE: 2048 points, vegetative
carbon: 6 points, soil carbon: 2048 points) (Fig. \ref{fig:rmsMAPObs}). While there are
clear differences in the RMS values versus the previous graph, as might be expected, the
broad-scale signature of increasing RMS difference for vegetative carbon and decreasing
RMS difference for NEE and soil carbon is retained. As before, this graph can be used to
diagnose when the imbalanced in data is starting to interact with the erroneous model. In
this case, as before, this occurs for a data quantity greater than 32.

```{r include=FALSE}
tt <- tibble::tibble ( istep=1:9)

obsSel <- c(1,202,390,550,750,920)*2.0

newPars["Av"]  <- 1.0
newPars["Cr"]  <- 0.0
BCMAPRMSObs <- tt %>% mutate(NEERMSErrunbal=map_dbl(istep,function(i) calcRMS(i,fldno=1,tselect=1:ndays,fld=obs,MAPfld=MAPErrunbal))) %>%
                      mutate(CvRMSErrunbal =map_dbl(istep,function(i) calcRMS(i,fldno=2,tselect=obsSel,fld=obs,MAPfld=MAPErrunbal))) %>%
                      mutate(CsRMSErrunbal =map_dbl(istep,function(i) calcRMS(i,fldno=3,tselect=1:ndays,fld=obs,MAPfld=MAPErrunbal))) %>%
                      mutate(noObs=map_int(istep,function(i) length(csel[[i]])))

p1 <- ggplot(data = BCMAPRMSObs, aes(x=noObs)) +
    geom_point(aes(y = NEERMSErrunbal,colour="Model with Error UnBal Data")) +
    geom_line (aes(y = NEERMSErrunbal,colour="Model with Error UnBal Data")) +
    labs(x = " ", y="RMS NEE")

p2 <- ggplot(data = BCMAPRMSObs, aes(x=noObs)) +
    geom_point(aes(y = CvRMSErrunbal,colour="Model with Error UnBal Data"))+
    geom_line (aes(y = CvRMSErrunbal,colour="Model with Error UnBal Data"))+ 
    labs(x = " ", y="RMS vegetative carbon")

p3 <- ggplot(data = BCMAPRMSObs, aes(x=noObs)) +
    geom_point(aes(y = CsRMSErrunbal,colour="Model with Error UnBal Data")) +
    geom_line (aes(y = CsRMSErrunbal,colour="Model with Error UnBal Data")) +
    labs(x = "Number of observations included in the calibration", y="RMS soil carbon")
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:rmsMAPObs}Each point in the three graphs (NEE, vegetative carbon, and soil carbon) represents the RMS difference between the VSEM model and virtual observations run with different maximum a posteriori (MAP) vectors. The MAP vector at each point is obtained from a Bayesian calibration (BC) where the quantity of data included in the BC for NEE and soil carbon increases in a sequence along the x-axis following the exponentiation of base two. The quantity of vegetaive carbon data is held fixed at six for all points in the graphs. The VSEM model used has a known error relative to the virtual observations that was derived from it."}
grid_arrange_shared_legend(p1, p2, p3, ncol = 1, nrow = 3)
```

# Changes to the Likelihood to represent model and data errors

## Model with error and unbalanced perfect data with additive and multiplicative parameters to represent model error. EuL
 * refer to Fig. (\ref{fig:errModunbalDatamodLikePar}) and (\ref{fig:errModunbalDatamodLikeOut})
 * KEXT, LUE, Cv, Cs and error-coeffVar are now significantly closer to the 'true' values. tauS is not but is much more uncertain. 
 * vegetative carbon much improved 
     * 5 out of 6 data points are now inside the posterior confidence interval
     * 50% quantile line now much closer to the 'true' line.

 
```{r include=FALSE}
addPars                   <- refPars
addPars[nvar+1,]          <- c(1.0, 0.1, 2.0)
addPars[nvar+2,]          <- c(1.0, 0.1, 2.0)
addPars[nvar+3,]          <- c(0.0, -0.01, 0.01)
addPars[nvar+4,]          <- c(0.0, -1.0, 1.0)
rownames(addPars)[nvar+1]   <- "modmultNEE"
rownames(addPars)[nvar+2]   <- "modmultCs"
rownames(addPars)[nvar+3]   <- "modaddNEE"
rownames(addPars)[nvar+4]   <- "modaddCs"
newPars <- addPars$best
names(newPars) = row.names(addPars)
newPars["Av"]  <- 1.0
newPars["Cr"]  <- 0.0
parSel = c(defParms, nvar,nvar+1,nvar+2,nvar+3,nvar+4)
npar <- length(parSel)
obsSel <- c(1,202,390,550,750,920)*2
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:(nvar-1)], PAR)

  diff       <- c((predicted[,1]*x[nvar+1] + x[nvar+3]) - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(((predicted[1,3] + (predicted[,3] - predicted[1,3])*x[nvar+2]) + x[nvar+4]) - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = addPars$lower[parSel], upper = addPars$upper[parSel])
out15 <- fitVSEM("run15.RData",iter=1200000, params=addPars)
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:errModunbalDatamodLikePar}Model with error and unbalanced data with additive and multiplicative parameters to represent model error. Marginal posterior distribution of model parameters and intital states. The red line marks the 'true' parameter values."}
plotParametersEsys(out15,addPars)
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:errModunbalDatamodLikeOut}Model with error and unbalanced data with additive and multiplicative parameters to represent model error. Observations included in the calibration marked with a '+'. Red line 50% quantile posterior distribution. Green line is the 'true' model output. Dark brown shading 2.5% 97.5% quantile posterior distribution. Light brown shading 2.5% 97.5% predictive interval."}
plotOutputsEsys(out15,addPars)
```

## Perfect model and and unbalanced data with a multiplicative bias and additive and multiplicative parameters to represent the bias. PuBL
  * refer to Fig. (\ref{fig:perModunbalDataBiasmodLikePar}) and (\ref{fig:perModunbalDataBiasmodLikeOut}) 
  * many model parameters (KEXT, LUE, tauV, tauS, initial Cv) much closer to 'true' values
  * multiplicative bias multiplication parameter modmultCs centred around 2.25 which is close to the multiplication factor applied to the data. 
  * NEE and soil carbon close to the data and within the predictive interval.
  * vegetative carbon pool much improved with all data points covered by the posterior credible interval.
 
```{r include=FALSE}
obs[,3] <- obs[,3] * 2.0

addPars                   <- refPars
addPars[nvar+1,]          <- c(1.0, 0.1, 3.0)
addPars[nvar+2,]          <- c(1.0, 0.1, 3.0)
addPars[nvar+3,]          <- c(0.0, -0.01, 0.01)
addPars[nvar+4,]          <- c(0.0, -1.0, 1.0)
rownames(addPars)[nvar+1]   <- "modmultNEE"
rownames(addPars)[nvar+2]   <- "modmultCs"
rownames(addPars)[nvar+3]   <- "modaddNEE"
rownames(addPars)[nvar+4]   <- "modaddCs"
newPars <- addPars$best
names(newPars) = row.names(addPars)
parSel = c(defParms, nvar,nvar+1,nvar+2,nvar+3,nvar+4)
npar <- length(parSel)
obsSel <- c(1,202,390,550,750,920)*2
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaultsOld(x, newPars, parSel)
  predicted <- VSEM(x[1:(nvar-1)], PAR)

  diff       <- c((predicted[,1]*x[nvar+1] + x[nvar+3]) - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(((predicted[1,3] + (predicted[,3] - predicted[1,3])*x[nvar+2]) + x[nvar+4]) - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = addPars$lower[parSel], upper = addPars$upper[parSel])

out16 <- fitVSEM("run16.RData",params=addPars)
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:perModunbalDataBiasmodLikePar}Perfect model and and unbalanced data with a multiplicative bias and additive and multiplicative parameters to represent the bias. Marginal posterior distribution of model parameters and intital states. The red line marks the 'true' parameter values."}
plotParametersEsys(out16,addPars)
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:perModunbalDataBiasmodLikeOut}Perfect model and and unbalanced data with a multiplicative bias and additive and multiplicative parameters to represent the bias. Observations included in the calibration marked with a '+'. Red line 50% quantile posterior distribution. Green line is the 'true' model output. Dark brown shading 2.5% 97.5% quantile posterior distribution. Light brown shading 2.5% 97.5% predictive interval."}
plotOutputsEsys(out16,addPars)
obs <- obs.orig
```

## Model with error and and unbalanced data with a multiplicative bias and additive and multiplicative parameters to represent model error and the data bias. EuBL

```{r include=FALSE}
obs[,3] <- obs[,3] * 2.0
   
addPars                   <- refPars
addPars[nvar+1,]          <- c(1.0, 0.1, 3.0)
addPars[nvar+2,]          <- c(1.0, 0.1, 3.0)
addPars[nvar+3,]          <- c(0.0, -0.01, 0.01)
addPars[nvar+4,]          <- c(0.0, -1.0, 1.0)
rownames(addPars)[nvar+1]   <- "modmultNEE"
rownames(addPars)[nvar+2]   <- "modmultCs"
rownames(addPars)[nvar+3]   <- "modaddNEE"
rownames(addPars)[nvar+4]   <- "modaddCs"
newPars <- addPars$best
names(newPars) = row.names(addPars)
newPars["Av"]  <- 1.0
newPars["Cr"]  <- 0.0
parSel = c(defParms, nvar,nvar+1,nvar+2,nvar+3,nvar+4)
npar <- length(parSel)
obsSel <- c(1,202,390,550,750,920)*2
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaultsOld(x, newPars, parSel)
  predicted <- VSEM(x[1:(nvar-1)], PAR)

  diff       <- c((predicted[,1]*x[nvar+1] + x[nvar+3]) - obs[,1])
  llValues1  <- dnorm(diff, sd = pmax((abs(c(predicted[,1])) + 0.0000001) * x[nvar],0.0005), log = T)
  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T)
  diff       <- c(((predicted[1,3] + (predicted[,3] - predicted[1,3])*x[nvar+2]) + x[nvar+4]) - obs[,3])
  llValues3  <- dnorm(diff, sd = (abs(c(predicted[,3])) + 0.0000001) * x[nvar], log = T)

  ## if (sum == FALSE) return(llValues)
  ## else return(sum(llValues1,llValues2,llValues3))
  return(sum(llValues1,llValues2,llValues3))
}

prior         <- createUniformPrior(lower = addPars$lower[parSel], upper = addPars$upper[parSel])

out18 <- fitVSEM("run18.RData",iter=1200000,params=addPars)
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:errModunbalDataBiasmodLikePar}Model with error and and unbalanced data with a multiplicative bias and additive and multiplicative parameters to represent model error and the data bias. Marginal posterior distribution of model parameters and intital states. The red line marks the 'true' parameter values."}
plotParametersEsys(out18,addPars)
```

```{r echo=FALSE, background='white', fig.height=7, fig.cap="\\label{fig:errModunbalDataBiasmodLikeOut}Model with error and and unbalanced data with a multiplicative bias and additive and multiplicative parameters to represent model error and the data bias. Observations included in the calibration marked with a '+'. Red line 50% quantile posterior distribution. Green line is the 'true' model output. Dark brown shading 2.5% 97.5% quantile posterior distribution. Light brown shading 2.5% 97.5% predictive interval."}
plotOutputsEsys(out18,addPars)
obs <- obs.orig
```

 * refer to Fig. (\ref{fig:errModunbalDataBiasmodLikePar}) and (\ref{fig:errModunbalDataBiasmodLikeOut}) 
 * as above many parameters improved (KEXT, LUE, tauS, initial Cv)
 * modmultCs value centered ~1.8 compromise between value in Fig. (\ref{fig:perModunbalDataBiasmodLikePar}) for bias only and Fig. (\ref{fig:errModunbalDatamodLikePar}) model error only. 
 * vegetative pool much improved with 
     * 5 out of 6 data points within posterior credible interval
     * 50% quantile line now much closer to the 'true' line.
     * similar to Fig. (\ref{fig:errModunbalDatamodLikeOut}) 
