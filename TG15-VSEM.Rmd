---
title: "Experiments for TG15 with VSEM"
author: "David Cameron and Mike Dietze"
date: '`r Sys.Date()`'
output:
  beamer_presentation:
             includes:
               in_header: mystyles.sty
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
  html_document: default
  word_document: default
---

```{r include=FALSE}
library(BayesianTools)
CLEAN.BUILD = FALSE
PLOT.DIAGNOSTICS = TRUE
```

```{r include=FALSE}
plotTimeSeriesResults <- function(x, model, observed, error = NULL, plotResiduals = T, start = 1,pool=1){
  
  if(inherits(x,"bayesianOutput")) parMatrix = getSample(x, start = start)
  else if (class(sampler) == "matrix") parMatrix = sampler
  else stop("wrong type give to variable sampler")
  
  myModel <- function(x) model(x,pool)
  pred <- getPredictiveIntervals(parMatrix = parMatrix, model = myModel, thin = 1000, quantiles = c(0.025, 0.5, 0.975), error = error)
  
  plotTimeSeries(observed = observed, predicted = pred[2,], confidenceBand = pred[c(1,3),])
  lines(pred[2,],col="red",lwd=2)
}

```
# The TG15 issue
![](moderrunbal.pdf)

# What is the effective information content (IC) of observations
 - One eddy covariance tower with 17000 measurements count this as n = 1 or n = 17000 obs?
 - Aggregate 5 min data to 10 min retain essentially same IC but sample size halved!
 - Spectral analysis of eddy covariance NEE data two peaks: annual(seasonal) and diurnal
 - Often assume in BC that each data-point provides independent information
 - If biases in data or model errors are not independent

# To-date solutions generally ad hoc and/or arbitrary
  - Ignore but then models over-fitted and uncertainty underestimated
  - Apply arbitrary weights to rebalance influence of data in BC 
  - Thin the number of eddy covariance obs 
   - throwing away useful information

# Thin observations 6 obs
![](6obs.pdf
)

# Artificial experiments
 - calibration data model's own output to control:
  1) model and data perfection/imperfection
  2) balance/unbalance of data in the calibration
 - developed a very simple ecosystem model (VSEM)  

# VSEM
## Photosynthesis

\begin{align}
GPP &= PAR \times LUE \times (1 - \exp^{(-KEXT \times LAI)})\\
NPP &= (1-GAMMA) \times GPP
\end{align}

 - PAR Photosynthetically active radiation
 - LUE Light use efficiency 
 - KEXT Beer's law light extinction coeff

# VSEM
## C-state equations
\begin{align}
\frac{dC_v}{dt}  &= A_v \times NPP &- \frac{C_v}{\tau_v} \\ 
\frac{dC_r}{dt}  &= (1.0-A_v) \times NPP &- \frac{C_r}{\tau_r}\\
\frac{dC_s}{dt}  &= \frac{C_r}{\tau_r} + \frac{C_v}{\tau_v} &- \frac{C_s}{\tau_s}
\end{align}
 - $C_v$, $C_r$ and $C_s$ : Carbon in vegetation, root and soil pools 

```{r include=FALSE}
## HELPER FUNCTIONS

fitVSEM <- function(fname){
  if(!file.exists(fname)|CLEAN.BUILD){
    bayesianSetup <- createBayesianSetup(likelihood, prior,best = newPars[parSel], names = rownames(refPars)[parSel])
    settings = list(iterations = 10000)
    out <- runMCMC(bayesianSetup = bayesianSetup, sampler = "DREAMzs", settings = settings)
    save(out,file=fname)
  } else {
    load(fname)
  }
  invisible(out)
}

runModel <- function(par,pool){
  x = createMixWithDefaults(par, newPars, parSel)
  predicted <- VSEM(x[1:11], PAR)
  return(predicted[,pool])
}

errorFunction <- function(mean, par) rnorm(length(mean), mean = mean, sd = abs(mean)*par[length(par)])

plotPosteriors <- function(out,refPars){
  np = length(parSel)  ## number of parameters fit
  outM <- as.matrix(out$chain)[,1:np]
  colnames(outM) <- rownames(refPars)[parSel]
  for(i in 1:np){
    true = refPars[parSel[i],1]
    d = density(outM[,i])
    xlim = range(c(d$x,true))
    plot(d,xlim=xlim,main=colnames(outM)[i])
    abline(v=true,col=2,lwd=3)
  }
}

vsemDiagnostics <- function(out,refPars){
  ## thin
  nmc = nrow(out$chain[[1]])
  out$chain <- window(out$chain,start=nmc/2,thin=(nmc/2)/5000)

  par(mfrow = c(2,2))
  for(i in 1:3){
    myObs = obs[,i]
    if(exists("obsSel") & i %in% isLow) myObs[-obsSel] <- NA
    plotTimeSeriesResults(x = out, model = runModel, observed = myObs, error = errorFunction,pool=i)
    lines(referenceData[,i],col=3,lwd=1)
  }
  
  if(PLOT.DIAGNOSTICS){
    
    #plot(out$chain)
    
    par(mfrow=c(3,2))
    plotPosteriors(out,refPars)
    
    par(mfrow=c(1,1))
    correlationPlot(out)
  }
}
```


# Idealised experiment with virtual data from VSEM
 - Run model with a parameter vector output assign as 'truth'
 - Add noise to create idealised observations

```{r include=FALSE}
if(!file.exists("obs.RData")|CLEAN.BUILD){
  set.seed(123)
  ## ndays                 <- 366
  ndays                 <- 1000
  PAR                   <- VSEMcreatePAR(1:ndays)
  refPars               <- VSEMgetDefaults()
  ## merge non-identifiable parameters
  refPars[1,] <- refPars[1,]*refPars[2,]
  refPars[3,] <- refPars[3,]*(1-refPars[4,c(1,3,2)])
  refPars <- refPars[-c(2,4),] 
  nvar = nrow(refPars)+1
  ## add SD
  refPars[nvar,]          <- c(0.1, 0.001, 0.5)
  rownames(refPars)[nvar] <- "error-sd"
  ## calculate 'true' output and pseudodata
  referenceData         <- VSEM(refPars$best[1:(nvar-1)], PAR,vers=2) 
  obs                   <- referenceData + rnorm(length(referenceData), sd = (abs(referenceData) + 1E-7) * refPars$best[nvar])
  save(ndays,PAR,refPars,referenceData,obs,file="obs.RData")
  if(PLOT.DIAGNOSTICS){
    par(mfrow=c(3,1))
    for(i in 1:3){
      plot(obs[,i])
      lines(referenceData[,i],col=3,lwd=3)
    }
  }
} else {
  load("obs.RData")
}
```

# Perfect model balanced perfect data 
Gaussian 1000 obs for each of NEE, Cv and Cs

```{r echo=FALSE, background='white', fig.height=7, fig.cap="Output from perfect model after calibration"}
newPars <- refPars$best
parSel = c(1:6, nvar)
rm(obsSel)
isLow = NULL
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[-nvar], PAR,vers=2)
  diff      <- c(predicted[,1:3] - obs[,1:3])
  llValues  <- dnorm(diff, sd = (abs(c(predicted[,1:3])) + 0.0000001) * x[nvar], log = T) 
  if (sum == FALSE) return(llValues)
  else return(sum(llValues))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])
out <- fitVSEM("run1.RData")
vsemDiagnostics(out,refPars)
```

# Perfect model unbalanced perfect data 
## Likelihood 
Gaussian 1000 obs for NEE and Cs and only 6 for Cv

```{r include=FALSE,echo=FALSE, background='white', fig.height=7, fig.cap="Output from perfect model after calibration"}
newPars <- refPars$best
parSel = c(1:6, nvar)
obsSel <- c(1,202,390,550,750,920)
isLow = 2 ## which variables has few observations
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:(nvar-1)], PAR)
  diff       <- c(predicted[,c(1,3)] - obs[,c(1,3)])
  llValues1  <- dnorm(diff, sd = (abs(c(predicted[,c(1,3)])) + 0.0000001) * x[nvar], log = T) 

  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T) 

  if (sum == FALSE) return(llValues)
  else return(sum(llValues1,llValues2))
}

## Prior
prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out <- fitVSEM("run2.RData")

vsemDiagnostics(out,refPars)
```

# Model with error balanced perfect data (1000 obs) 
Remove the root pool by setting allocation to vegetation Av = 1.0


# Model with error balanced perfect data (1000 obs) - results
```{r echo=FALSE, background='white', fig.height=7, fig.cap="Output from error model after calibration"}

## Likelihood: Gaussian 1000 obs for each of NEE, Cv and Cs
newPars <- refPars$best
names(newPars) = row.names(refPars)
newPars["Av"]  <- 1.0
newPars["Cr"] <- 0.0
parSel = c(1:6, nvar)
rm(obsSel)
isLow = NULL
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:11], PAR)
  diff      <- c(predicted[,1:3] - obs[,1:3])
  llValues  <- dnorm(diff, sd = (abs(c(predicted[,1:3])) + 0.0000001) * x[nvar], log = T) 
  if (sum == FALSE) return(llValues)
  else return(sum(llValues))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out <- fitVSEM("run3.RData")

vsemDiagnostics(out,refPars)
```

# Model with error balanced perfect data (6 obs) 
Remove the root pool by setting allocation to vegetation Av = 1.0

## Likelihood 
Gaussian 6 obs for each of NEE, Cv and Cs

```{r echo=FALSE, background='white', fig.height=7, fig.cap="Output from perfect model after calibration"}
newPars <- refPars$best
names(newPars) = row.names(refPars)
newPars["Av"]  <- 1.0
newPars["Cr"] <- 0.0
parSel = c(1:6, nvar)
obsSel <- c(1,202,390,550,750,920)
isLow = 1:3
## obsSel = seq(1,366,72)
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:11], PAR)
  diff      <- c(predicted[obsSel,1:3] - obs[obsSel,1:3])
  llValues  <- dnorm(diff, sd = (abs(c(predicted[obsSel,1:3])) + 0.0000001) * x[nvar], log = T) 
  if (sum == FALSE) return(llValues)
  else return(sum(llValues))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])
out <- fitVSEM("run4.RData")
vsemDiagnostics(out,refPars)
```

# Model with error unbalanced perfect data 
Remove the root pool by setting allocation to vegetation Av = 1.0

## Likelihood 
Gaussian 1000 obs for NEE and Cs and only 6 for Cv

```{r include=FALSE}
newPars <- refPars$best
names(newPars) = row.names(refPars)
newPars["Av"]  <- 1.0
newPars["Cr"] <- 0.0
parSel = c(1:6, nvar)
obsSel <- c(1,202,390,550,750,920)
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:11], PAR)
  diff       <- c(predicted[,c(1,3)] - obs[,c(1,3)])
  llValues1  <- dnorm(diff, sd = (abs(c(predicted[,c(1,3)])) + 0.0000001) * x[nvar], log = T) 

  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T) 

  if (sum == FALSE) return(llValues)
  else return(sum(llValues1,llValues2))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out <- fitVSEM("run5.RData")
vsemDiagnostics(out,refPars)

```

# Model with error unbalanced perfect data - results
![](moderrunbal.pdf)


# Perfect model balanced data that has an additive bias 
Cs obs have an additive error of 4

```{r echo=FALSE, background='white', fig.height=7, fig.cap="Output from perfect model after calibration"}
obs.orig <- obs
obs[,3] <- obs[,3] + 4.0

newPars <- refPars$best
parSel = c(1:6, nvar)
rm(obsSel)
isLow = NULL
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:11], PAR)
  diff      <- c(predicted[,1:3] - obs[,1:3])
  llValues  <- dnorm(diff, sd = (abs(c(predicted[,1:3])) + 0.0000001) * x[nvar], log = T) 
  if (sum == FALSE) return(llValues)
  else return(sum(llValues))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out <- fitVSEM("run6.RData")

vsemDiagnostics(out,refPars)

obs <- obs.orig
```

# Perfect model unbalanced data that has an additive bias
Cs obs have an additive error of 4

```{r include=FALSE}
obs <- obs.orig
obs[,3] <- obs[,3] + 4.0

newPars <- refPars$best
parSel = c(1:6, nvar)
obsSel <- c(1,202,390,550,750,920)
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:(nvar-1)], PAR)
  diff       <- c(predicted[,c(1,3)] - obs[,c(1,3)])
  llValues1  <- dnorm(diff, sd = (abs(c(predicted[,c(1,3)])) + 0.0000001) * x[nvar], log = T) 

  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T) 

  if (sum == FALSE) return(llValues)
  else return(sum(llValues1,llValues2))
}

prior         <- createUniformPrior(lower = refPars$lower[parSel], upper = refPars$upper[parSel])

out <- fitVSEM("run7.RData")

vsemDiagnostics(out,refPars)

obs <- obs.orig

```

![](TG15-clean_files/figure-beamer/unnamed-chunk-42-1.pdf)


# Perfect model unbalanced data that has an additive bias with systmatic bias parameter
Cs obs have an additive error of 4
Gaussian 1000 obs for NEE and Cs and only 6 for Cv

```{r include=FALSE}
obs <- obs.orig
obs[,3] <- obs[,3] + 4.0

addPars <- refPars
addPars[nvar+1,] <- c(4.0, 0.0, 12.0)
row.names(addPars)<-c(row.names(refPars),"EsysNEE")
newPars <- addPars$best
parSel = c(1:6, nvar,nvar+1)
obsSel <- c(1,202,390,550,750,920)
isLow = 2
likelihood <- function(x, sum = TRUE){
  x         <- createMixWithDefaults(x, newPars, parSel)
  predicted <- VSEM(x[1:(nvar-1)], PAR)
#  modobs[,3]<-modobs[,3]+(x[nvar+1]-6.0)
  predicted[,3] <- predicted[,3] + x[nvar+1]
  
  diff       <- c(predicted[,c(1,3)] - obs[,c(1,3)])
  llValues1  <- dnorm(diff, sd = (abs(c(predicted[,c(1,3)])) + 0.0000001) * x[nvar], log = T) 

  diff       <- c(predicted[obsSel,2] - obs[obsSel,2])
  llValues2  <- dnorm(diff, sd = (abs(c(predicted[obsSel,2])) + 0.0000001) * x[nvar], log = T) 

  if (sum == FALSE) return(llValues)
  else return(sum(llValues1,llValues2))
}


prior         <- createUniformPrior(lower = addPars$lower[parSel], upper = addPars$upper[parSel])

out <- fitVSEM("run8.RData")
vsemDiagnostics(out,addPars)

```

![](TG15-clean_files/figure-beamer/unnamed-chunk-48-1.pdf)


# Short term ideas
## Experiment that includes obs bias(es)
 - Additive and or multiplicative for now 
 - Add multiplicative/additive bias terms to model and obs

## Test other model errors?
 - for example: include/remove Q10 type soil respiration 

# Longer term ideas
## use the formalism of Rougier(2007) in BC
The idea here is to learn about the inclusion of errors by analysing model data mismatch. Correlations between the mismatches of NEE, Cv and Cs could then be included in the calibration 
via Gaussian $\mu$ and $\sigma$ terms using the formalism of Rougier(2007). 

## include GAMMS in BC

## calibrate a simplier model to the output of a more complex model
Before a calibration against real obs an experiment where we create virtual data form a complex data 
and try to fit a simple model using what we have learned already about how to include terms that represent 
model structural error in the BC. 



